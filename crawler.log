INFO main org.apache.spark.SparkContext - Running Spark version 2.2.1
INFO main org.apache.spark.SparkContext - Submitted application: local
INFO main org.apache.spark.SecurityManager - Changing view acls to: ningjianjian
INFO main org.apache.spark.SecurityManager - Changing modify acls to: ningjianjian
INFO main org.apache.spark.SecurityManager - Changing view acls groups to: 
INFO main org.apache.spark.SecurityManager - Changing modify acls groups to: 
INFO main org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ningjianjian); groups with view permissions: Set(); users  with modify permissions: Set(ningjianjian); groups with modify permissions: Set()
INFO main org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 62644.
INFO main org.apache.spark.SparkEnv - Registering MapOutputTracker
INFO main org.apache.spark.SparkEnv - Registering BlockManagerMaster
INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
INFO main org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
INFO main org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\ningjianjian\AppData\Local\Temp\blockmgr-582fedda-62b0-406f-947a-f0a39c08f03b
INFO main org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 901.8 MB
INFO main org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
INFO main org.spark_project.jetty.util.log - Logging initialized @3000ms
INFO main org.spark_project.jetty.server.Server - jetty-9.3.z-SNAPSHOT
INFO main org.spark_project.jetty.server.Server - Started @3070ms
INFO main org.spark_project.jetty.server.AbstractConnector - Started ServerConnector@2210468b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
INFO main org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6f70f32f{/jobs,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1b822fcc{/jobs/json,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@56102e1c{/jobs/job,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@532721fd{/jobs/job/json,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@7fb9f71f{/stages,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@51f49060{/stages/json,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@617fe9e1{/stages/stage,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@245a26e1{/stages/stage/json,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@466cf502{/stages/pool,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2e185cd7{/stages/pool/json,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5f7f2382{/storage,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6815c5f2{/storage/json,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60094a13{/storage/rdd,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1c32886a{/storage/rdd/json,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@10b892d5{/environment,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3546d80f{/environment/json,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3670f00{/executors,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@46ab18da{/executors/json,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@42257bdd{/executors/threadDump,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@687a762c{/executors/threadDump/json,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@733c423e{/static,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1f130eaf{/,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21362712{/api,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1494b84d{/jobs/job/kill,null,AVAILABLE,@Spark}
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@71a9b4c7{/stages/stage/kill,null,AVAILABLE,@Spark}
INFO main org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.12.1:4040
INFO main org.apache.spark.executor.Executor - Starting executor ID driver on host localhost
INFO main org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 62653.
INFO main org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.12.1:62653
INFO main org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
INFO main org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.12.1, 62653, None)
INFO dispatcher-event-loop-2 org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.12.1:62653 with 901.8 MB RAM, BlockManagerId(driver, 192.168.12.1, 62653, None)
INFO main org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.12.1, 62653, None)
INFO main org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.12.1, 62653, None)
INFO main org.spark_project.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@78c7f9b3{/metrics/json,null,AVAILABLE,@Spark}
INFO main org.apache.spark.SparkContext - Starting job: collect at SparkTransformationTest.java:50
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (collect at SparkTransformationTest.java:50) with 5 output partitions
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (collect at SparkTransformationTest.java:50)
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[1] at mapPartitionsWithIndex at SparkTransformationTest.java:36), which has no missing parents
INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 2.9 KB, free 901.8 MB)
INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 1757.0 B, free 901.8 MB)
INFO dispatcher-event-loop-0 org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 192.168.12.1:62653 (size: 1757.0 B, free: 901.8 MB)
INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1006
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at mapPartitionsWithIndex at SparkTransformationTest.java:36) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4))
INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 5 tasks
INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 4837 bytes)
INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
INFO Executor task launch worker for task 0 org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 714 bytes result sent to driver
INFO dispatcher-event-loop-3 org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 4847 bytes)
INFO Executor task launch worker for task 1 org.apache.spark.executor.Executor - Running task 1.0 in stage 0.0 (TID 1)
INFO Executor task launch worker for task 1 org.apache.spark.executor.Executor - Finished task 1.0 in stage 0.0 (TID 1). 671 bytes result sent to driver
INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 0.0 (TID 2, localhost, executor driver, partition 2, PROCESS_LOCAL, 4837 bytes)
INFO Executor task launch worker for task 2 org.apache.spark.executor.Executor - Running task 2.0 in stage 0.0 (TID 2)
INFO Executor task launch worker for task 2 org.apache.spark.executor.Executor - Finished task 2.0 in stage 0.0 (TID 2). 628 bytes result sent to driver
INFO dispatcher-event-loop-3 org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 0.0 (TID 3, localhost, executor driver, partition 3, PROCESS_LOCAL, 4847 bytes)
INFO Executor task launch worker for task 3 org.apache.spark.executor.Executor - Running task 3.0 in stage 0.0 (TID 3)
INFO Executor task launch worker for task 3 org.apache.spark.executor.Executor - Finished task 3.0 in stage 0.0 (TID 3). 629 bytes result sent to driver
INFO dispatcher-event-loop-0 org.apache.spark.scheduler.TaskSetManager - Starting task 4.0 in stage 0.0 (TID 4, localhost, executor driver, partition 4, PROCESS_LOCAL, 4847 bytes)
INFO Executor task launch worker for task 4 org.apache.spark.executor.Executor - Running task 4.0 in stage 0.0 (TID 4)
INFO Executor task launch worker for task 4 org.apache.spark.executor.Executor - Finished task 4.0 in stage 0.0 (TID 4). 672 bytes result sent to driver
INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 149 ms on localhost (executor driver) (1/5)
INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 4.0 in stage 0.0 (TID 4) in 13 ms on localhost (executor driver) (2/5)
INFO task-result-getter-3 org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 0.0 (TID 3) in 20 ms on localhost (executor driver) (3/5)
INFO task-result-getter-2 org.apache.spark.scheduler.TaskSetManager - Finished task 2.0 in stage 0.0 (TID 2) in 29 ms on localhost (executor driver) (4/5)
INFO task-result-getter-1 org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 0.0 (TID 1) in 36 ms on localhost (executor driver) (5/5)
INFO task-result-getter-1 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (collect at SparkTransformationTest.java:50) finished in 0.176 s
INFO main org.apache.spark.scheduler.DAGScheduler - Job 0 finished: collect at SparkTransformationTest.java:50, took 0.395493 s
INFO Thread-1 org.apache.spark.SparkContext - Invoking stop() from shutdown hook
INFO Thread-1 org.spark_project.jetty.server.AbstractConnector - Stopped Spark@2210468b{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
INFO Thread-1 org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.12.1:4040
INFO dispatcher-event-loop-1 org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
INFO Thread-1 org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
INFO Thread-1 org.apache.spark.storage.BlockManager - BlockManager stopped
INFO Thread-1 org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
INFO dispatcher-event-loop-3 org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
INFO Thread-1 org.apache.spark.SparkContext - Successfully stopped SparkContext
INFO Thread-1 org.apache.spark.util.ShutdownHookManager - Shutdown hook called
INFO Thread-1 org.apache.spark.util.ShutdownHookManager - Deleting directory C:\Users\ningjianjian\AppData\Local\Temp\spark-6e043c3b-761b-4916-ba82-5cb46f2a9e4a
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1918925513_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1918925513_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1918925513_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7f865dd0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+26
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 77; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214372(104857488); length = 25/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1918925513_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1918925513_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1918925513_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1918925513_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7734a2ef
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@18daa432
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1918925513_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1918925513_0001_m_000000_0 decomp: 54 len: 58 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 54 bytes from map-output for attempt_local1918925513_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 54, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->54
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 44 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 54 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 58 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 44 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1918925513_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1918925513_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1918925513_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output.txt/_temporary/0/task_local1918925513_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1918925513_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1918925513_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1918925513_0001_r_000001_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@26800974
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3d33b41e
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1918925513_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1918925513_0001_m_000000_0 decomp: 41 len: 45 to MEMORY
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 41 bytes from map-output for attempt_local1918925513_0001_m_000000_0
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 41, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->41
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 31 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 41 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 45 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 31 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1918925513_0001_r_000001_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1918925513_0001_r_000001_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1918925513_0001_r_000001_0' to file:/C:/Users/ningjianjian/Desktop/custom/output.txt/_temporary/0/task_local1918925513_0001_r_000001
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1918925513_0001_r_000001_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1918925513_0001_r_000001_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1918925513_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1918925513_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1171
		FILE: Number of bytes written=887093
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=7
		Map output records=7
		Map output bytes=77
		Map output materialized bytes=103
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=103
		Reduce input records=7
		Reduce output records=2
		Spilled Records=14
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=698351616
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=26
	File Output Format Counters 
		Bytes Written=64
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1751025252_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1751025252_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1751025252_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@413db124
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1907
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
ERROR LocalJobRunner Map Task Executor #0 com.ning.hadoop.customrecordreader.parsencbi.custom.CombineSequenceJob - map@CombineSequenceJob, map task error.
java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.LongWritable, received com.ning.hadoop.customrecordreader.parsencbi.model.BigText
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1074)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.ning.hadoop.customrecordreader.parsencbi.custom.CombineSequenceJob$PreprocessMapper.map(CombineSequenceJob.java:80)
	at com.ning.hadoop.customrecordreader.parsencbi.custom.CombineSequenceJob$PreprocessMapper.map(CombineSequenceJob.java:37)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
ERROR LocalJobRunner Map Task Executor #0 com.ning.hadoop.customrecordreader.parsencbi.custom.CombineSequenceJob - map@CombineSequenceJob, map task error.
java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.LongWritable, received com.ning.hadoop.customrecordreader.parsencbi.model.BigText
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1074)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.ning.hadoop.customrecordreader.parsencbi.custom.CombineSequenceJob$PreprocessMapper.map(CombineSequenceJob.java:80)
	at com.ning.hadoop.customrecordreader.parsencbi.custom.CombineSequenceJob$PreprocessMapper.map(CombineSequenceJob.java:37)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
ERROR LocalJobRunner Map Task Executor #0 com.ning.hadoop.customrecordreader.parsencbi.custom.CombineSequenceJob - map@CombineSequenceJob, map task error.
java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.LongWritable, received com.ning.hadoop.customrecordreader.parsencbi.model.BigText
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1074)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.ning.hadoop.customrecordreader.parsencbi.custom.CombineSequenceJob$PreprocessMapper.map(CombineSequenceJob.java:80)
	at com.ning.hadoop.customrecordreader.parsencbi.custom.CombineSequenceJob$PreprocessMapper.map(CombineSequenceJob.java:37)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
ERROR LocalJobRunner Map Task Executor #0 com.ning.hadoop.customrecordreader.parsencbi.custom.CombineSequenceJob - map@CombineSequenceJob, map task error.
java.io.IOException: Type mismatch in key from map: expected org.apache.hadoop.io.LongWritable, received com.ning.hadoop.customrecordreader.parsencbi.model.BigText
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1074)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.ning.hadoop.customrecordreader.parsencbi.custom.CombineSequenceJob$PreprocessMapper.map(CombineSequenceJob.java:80)
	at com.ning.hadoop.customrecordreader.parsencbi.custom.CombineSequenceJob$PreprocessMapper.map(CombineSequenceJob.java:37)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1751025252_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1751025252_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1751025252_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1751025252_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@46bcb5f8
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1deada26
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1751025252_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1751025252_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local1751025252_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1751025252_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1751025252_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1751025252_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1751025252_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1751025252_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1751025252_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1751025252_0001_r_000001_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@105caa60
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@ba9d00f
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1751025252_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1751025252_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local1751025252_0001_m_000000_0
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1751025252_0001_r_000001_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1751025252_0001_r_000001_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1751025252_0001_r_000001_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1751025252_0001_r_000001
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1751025252_0001_r_000001_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1751025252_0001_r_000001_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1751025252_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1751025252_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=12153
		FILE: Number of bytes written=885939
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=707788800
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=16
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1107322412_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1107322412_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1107322412_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3e781860
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1107322412_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1107322412_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1107322412_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1107322412_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@42d32228
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1166888d
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1107322412_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1107322412_0001_m_000000_0 decomp: 926 len: 930 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 926 bytes from map-output for attempt_local1107322412_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 926, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->926
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 840 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 926 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 930 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 840 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1107322412_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1107322412_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1107322412_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1107322412_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1107322412_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1107322412_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1107322412_0001_r_000001_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@16d68b6f
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1cc876eb
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1107322412_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1107322412_0001_m_000000_0 decomp: 1020 len: 1024 to MEMORY
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1020 bytes from map-output for attempt_local1107322412_0001_m_000000_0
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1020, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1020
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 890 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1020 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1024 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 890 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1107322412_0001_r_000001_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1107322412_0001_r_000001_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1107322412_0001_r_000001_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1107322412_0001_r_000001
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1107322412_0001_r_000001_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1107322412_0001_r_000001_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1107322412_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1107322412_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=14227
		FILE: Number of bytes written=898594
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1925
		Map output materialized bytes=1954
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1954
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=698351616
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=1917
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1496539735_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1496539735_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1496539735_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@731d843f
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1496539735_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1496539735_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1496539735_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1496539735_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1496539735_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@58a05d8f
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@68e0b5b3
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1496539735_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1496539735_0001_m_000000_0 decomp: 926 len: 930 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 926 bytes from map-output for attempt_local1496539735_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 926, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->926
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 840 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 926 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 930 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 840 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1496539735_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1496539735_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1496539735_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1496539735_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1496539735_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1496539735_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1496539735_0001_r_000001_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5a64fc91
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7fcbd200
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1496539735_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1496539735_0001_m_000000_0 decomp: 1020 len: 1024 to MEMORY
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1020 bytes from map-output for attempt_local1496539735_0001_m_000000_0
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1020, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1020
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 890 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1020 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1024 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 890 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1496539735_0001_r_000001_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1496539735_0001_r_000001_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1496539735_0001_r_000001_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1496539735_0001_r_000001
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1496539735_0001_r_000001_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1496539735_0001_r_000001_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1496539735_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=14227
		FILE: Number of bytes written=898594
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1925
		Map output materialized bytes=1954
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1954
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=808452096
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=1917
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local898095852_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local898095852_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local898095852_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@16fe6077
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO main org.apache.hadoop.mapreduce.Job - Job job_local898095852_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map > sort
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO communication thread org.apache.hadoop.mapred.LocalJobRunner - map > sort
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local898095852_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local898095852_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local898095852_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local898095852_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5f5b28cc
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5fba9b0d
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local898095852_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local898095852_0001_m_000000_0 decomp: 926 len: 930 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 926 bytes from map-output for attempt_local898095852_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 926, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->926
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 840 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 926 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 930 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 840 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local898095852_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local898095852_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local898095852_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local898095852_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local898095852_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local898095852_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local898095852_0001_r_000001_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7e7c97b5
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7255c869
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local898095852_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local898095852_0001_m_000000_0 decomp: 1020 len: 1024 to MEMORY
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1020 bytes from map-output for attempt_local898095852_0001_m_000000_0
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1020, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1020
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 890 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1020 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1024 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 890 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local898095852_0001_r_000001_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local898095852_0001_r_000001_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local898095852_0001_r_000001_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local898095852_0001_r_000001
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local898095852_0001_r_000001_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local898095852_0001_r_000001_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local898095852_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=14227
		FILE: Number of bytes written=894034
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1925
		Map output materialized bytes=1954
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1954
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=693633024
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=1917
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local499034005_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local499034005_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local499034005_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7fcc2fef
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1910; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local499034005_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local499034005_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local499034005_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local499034005_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4c3066b0
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2e8c37dd
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local499034005_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local499034005_0001_m_000000_0 decomp: 1929 len: 1933 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1929 bytes from map-output for attempt_local499034005_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1929, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1929
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1843 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1929 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1933 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1843 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local499034005_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local499034005_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local499034005_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local499034005_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local499034005_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local499034005_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local499034005_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local499034005_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8060
		FILE: Number of bytes written=595963
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1910
		Map output materialized bytes=1933
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1933
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=1894
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local554151658_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local554151658_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local554151658_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@33fac21b
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO main org.apache.hadoop.mapreduce.Job - Job job_local554151658_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1910; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local554151658_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local554151658_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local554151658_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local554151658_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7f42cb8e
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3a925bda
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local554151658_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local554151658_0001_m_000000_0 decomp: 1929 len: 1933 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1929 bytes from map-output for attempt_local554151658_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1929, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1929
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1843 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1929 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1933 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1843 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
WARN Thread-3 org.apache.hadoop.mapred.LocalJobRunner - job_local554151658_0001
java.lang.Exception: java.util.NoSuchElementException: iterate past last value
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.util.NoSuchElementException: iterate past last value
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl$ValueIterator.next(ReduceContextImpl.java:235)
	at com.ning.hadoop.customrecordreader.my.MyCustomRecordReaderReduce.reduce(MyCustomRecordReaderReduce.java:21)
	at com.ning.hadoop.customrecordreader.my.MyCustomRecordReaderReduce.reduce(MyCustomRecordReaderReduce.java:16)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:171)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run$$$capture(FutureTask.java:266)
	at java.util.concurrent.FutureTask.run(FutureTask.java)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
INFO main org.apache.hadoop.mapreduce.Job - Job job_local554151658_0001 failed with state FAILED due to: NA
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2081
		FILE: Number of bytes written=296068
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1910
		Map output materialized bytes=1933
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=1933
		Reduce input records=0
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=268435456
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=0
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1023389743_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1023389743_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1023389743_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@92702bf
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1910; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1023389743_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1023389743_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1023389743_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1023389743_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@59480d0a
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@57dc2027
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1023389743_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1023389743_0001_m_000000_0 decomp: 1929 len: 1933 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1929 bytes from map-output for attempt_local1023389743_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1929, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1929
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1843 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1929 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1933 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1843 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1023389743_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1023389743_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1023389743_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1023389743_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1023389743_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1023389743_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1023389743_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1023389743_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8060
		FILE: Number of bytes written=599003
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1910
		Map output materialized bytes=1933
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1933
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=470810624
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=1894
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local417310616_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local417310616_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local417310616_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@531a0a36
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1910; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local417310616_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local417310616_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local417310616_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local417310616_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@50e218c6
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5216268b
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local417310616_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local417310616_0001_m_000000_0 decomp: 1929 len: 1933 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1929 bytes from map-output for attempt_local417310616_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1929, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1929
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1843 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1929 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1933 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1843 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO main org.apache.hadoop.mapreduce.Job - Job job_local417310616_0001 running in uber mode : false
INFO communication thread org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO communication thread org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local417310616_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local417310616_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local417310616_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local417310616_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local417310616_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local417310616_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local417310616_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8060
		FILE: Number of bytes written=595963
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1910
		Map output materialized bytes=1933
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1933
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=1894
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local409808323_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local409808323_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local409808323_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7dfaac49
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO main org.apache.hadoop.mapreduce.Job - Job job_local409808323_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local409808323_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local409808323_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local409808323_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local409808323_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@191970c9
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@179aa21c
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local409808323_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local409808323_0001_m_000000_0 decomp: 1944 len: 1948 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1944 bytes from map-output for attempt_local409808323_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1944, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1944
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1944 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1948 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local409808323_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local409808323_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local409808323_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local409808323_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local409808323_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local409808323_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local409808323_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8090
		FILE: Number of bytes written=596023
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1925
		Map output materialized bytes=1948
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1948
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=470810624
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=1909
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local751286459_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local751286459_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local751286459_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3e781860
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local751286459_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local751286459_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local751286459_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local751286459_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@46378643
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@52850848
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local751286459_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local751286459_0001_m_000000_0 decomp: 1944 len: 1948 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1944 bytes from map-output for attempt_local751286459_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1944, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1944
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1944 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1948 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local751286459_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local751286459_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local751286459_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local751286459_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local751286459_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local751286459_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local751286459_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local751286459_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8090
		FILE: Number of bytes written=595993
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1925
		Map output materialized bytes=1948
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1948
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=462422016
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=1879
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local110627574_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local110627574_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local110627574_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6eadadc5
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local110627574_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local110627574_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local110627574_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local110627574_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5e48c745
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@12ad219e
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local110627574_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local110627574_0001_m_000000_0 decomp: 1944 len: 1948 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1944 bytes from map-output for attempt_local110627574_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1944, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1944
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1944 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1948 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local110627574_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local110627574_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local110627574_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local110627574_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local110627574_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local110627574_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local110627574_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local110627574_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8090
		FILE: Number of bytes written=596434
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1925
		Map output materialized bytes=1948
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1948
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=538968064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=2320
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1390653905_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1390653905_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1390653905_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6eadadc5
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1390653905_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1390653905_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1390653905_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1390653905_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5e48c745
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@12ad219e
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1390653905_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1390653905_0001_m_000000_0 decomp: 1944 len: 1948 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1944 bytes from map-output for attempt_local1390653905_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1944, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1944
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1944 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1948 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1390653905_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1390653905_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1390653905_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1390653905_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1390653905_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1390653905_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1390653905_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1390653905_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8090
		FILE: Number of bytes written=599474
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1925
		Map output materialized bytes=1948
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1948
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=2320
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local846366617_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local846366617_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local846366617_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@30f160ee
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local846366617_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local846366617_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local846366617_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local846366617_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7c3437be
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1f013f39
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local846366617_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local846366617_0001_m_000000_0 decomp: 1944 len: 1948 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1944 bytes from map-output for attempt_local846366617_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1944, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1944
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1944 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1948 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local846366617_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local846366617_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local846366617_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local846366617_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local846366617_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local846366617_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local846366617_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local846366617_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8090
		FILE: Number of bytes written=596005
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1925
		Map output materialized bytes=1948
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1948
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=1891
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1081140449_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1081140449_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1081140449_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1b33abcf
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1081140449_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1081140449_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1081140449_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1081140449_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@59059989
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@b85db51
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1081140449_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1081140449_0001_m_000000_0 decomp: 1944 len: 1948 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1944 bytes from map-output for attempt_local1081140449_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1944, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1944
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1944 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1948 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1081140449_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 0%
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1081140449_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1081140449_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1081140449_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1081140449_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1081140449_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1081140449_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1081140449_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8090
		FILE: Number of bytes written=599045
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1925
		Map output materialized bytes=1948
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1948
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=538968064
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=1891
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local646079255_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local646079255_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local646079255_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6eadadc5
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local646079255_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local646079255_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local646079255_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local646079255_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@73fed896
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4a95c6f8
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local646079255_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local646079255_0001_m_000000_0 decomp: 1944 len: 1948 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1944 bytes from map-output for attempt_local646079255_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1944, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1944
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1944 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1948 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local646079255_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local646079255_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local646079255_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local646079255_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local646079255_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local646079255_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local646079255_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local646079255_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8090
		FILE: Number of bytes written=595997
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1925
		Map output materialized bytes=1948
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1948
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=1883
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1728304818_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1728304818_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1728304818_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2e2a9fc8
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+54302
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 54319; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1728304818_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1728304818_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1728304818_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1728304818_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@73fed896
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4a95c6f8
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1728304818_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1728304818_0001_m_000000_0 decomp: 54338 len: 54342 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 54338 bytes from map-output for attempt_local1728304818_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 54338, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->54338
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 54252 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 54338 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 54342 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 54252 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1728304818_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1728304818_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1728304818_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1728304818_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1728304818_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1728304818_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1728304818_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1728304818_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=217666
		FILE: Number of bytes written=807673
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=54319
		Map output materialized bytes=54342
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=54342
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=54302
	File Output Format Counters 
		Bytes Written=53337
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1468959927_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1468959927_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1468959927_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@13a58d28
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+54302
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1425; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1468959927_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1468959927_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1468959927_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1468959927_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@42d32228
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1166888d
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1468959927_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1468959927_0001_m_000000_0 decomp: 1440 len: 1444 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1440 bytes from map-output for attempt_local1468959927_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1440, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1440
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1354 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1440 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1444 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1354 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1468959927_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1468959927_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1468959927_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1468959927_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1468959927_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1468959927_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1468959927_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1468959927_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=111870
		FILE: Number of bytes written=597038
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=3
		Map output records=3
		Map output bytes=1425
		Map output materialized bytes=1444
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=1444
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=54302
	File Output Format Counters 
		Bytes Written=1396
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1500170003_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1500170003_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1500170003_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@46ce2942
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1500170003_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1500170003_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1500170003_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1500170003_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1d624357
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5d1285d8
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1500170003_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1500170003_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 2 bytes from map-output for attempt_local1500170003_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 6 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1500170003_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1500170003_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1500170003_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1500170003_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1500170003_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1500170003_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1500170003_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1500170003_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4206
		FILE: Number of bytes written=591336
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=8
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local184268559_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local184268559_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local184268559_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6eadadc5
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 876; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214392(104857568); length = 5/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local184268559_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local184268559_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local184268559_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local184268559_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5e48c745
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@12ad219e
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local184268559_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local184268559_0001_m_000000_0 decomp: 886 len: 890 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 886 bytes from map-output for attempt_local184268559_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 886, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->886
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 800 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 886 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 890 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 800 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local184268559_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local184268559_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local184268559_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local184268559_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local184268559_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local184268559_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local184268559_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local184268559_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5974
		FILE: Number of bytes written=591802
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=876
		Map output materialized bytes=890
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=890
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=862
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1988251963_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1988251963_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1988251963_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@57daf3a2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1988251963_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1988251963_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1988251963_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1988251963_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2d3ce0a1
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4f31c5fe
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1988251963_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1988251963_0001_m_000000_0 decomp: 1944 len: 1948 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1944 bytes from map-output for attempt_local1988251963_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1944, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1944
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1944 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1948 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1988251963_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1988251963_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1988251963_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1988251963_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1988251963_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1988251963_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1988251963_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1988251963_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8090
		FILE: Number of bytes written=599037
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1925
		Map output materialized bytes=1948
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1948
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=1883
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local72244656_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local72244656_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local72244656_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@13a58d28
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 12258; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local72244656_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local72244656_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local72244656_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local72244656_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7494acb1
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@48fcf218
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local72244656_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local72244656_0001_m_000000_0 decomp: 12266 len: 12270 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 12266 bytes from map-output for attempt_local72244656_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 12266, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12266
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 10721 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 12266 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 12270 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 10721 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local72244656_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local72244656_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local72244656_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local72244656_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local72244656_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local72244656_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local72244656_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local72244656_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=38862
		FILE: Number of bytes written=634357
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=12258
		Map output materialized bytes=12270
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=12270
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=12335
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local362015045_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local362015045_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local362015045_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@19ec180c
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local362015045_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local362015045_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local362015045_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local362015045_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@46378643
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@52850848
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local362015045_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local362015045_0001_m_000000_0 decomp: 1944 len: 1948 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1944 bytes from map-output for attempt_local362015045_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1944, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1944
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1944 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1948 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local362015045_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local362015045_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local362015045_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local362015045_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local362015045_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local362015045_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local362015045_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local362015045_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8090
		FILE: Number of bytes written=595997
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1925
		Map output materialized bytes=1948
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1948
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=1883
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local4828735_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local4828735_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local4828735_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1617846
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local4828735_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local4828735_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local4828735_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local4828735_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@53676bca
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@19e6278
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local4828735_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local4828735_0001_m_000000_0 decomp: 1944 len: 1948 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1944 bytes from map-output for attempt_local4828735_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1944, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1944
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1944 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1948 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local4828735_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local4828735_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local4828735_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local4828735_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local4828735_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local4828735_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local4828735_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local4828735_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8090
		FILE: Number of bytes written=590155
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1925
		Map output materialized bytes=1948
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1948
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=471859200
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=2121
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local815117721_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local815117721_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local815117721_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@643b2de0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local815117721_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local815117721_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local815117721_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local815117721_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@380226cc
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7b22eb7d
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local815117721_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local815117721_0001_m_000000_0 decomp: 1944 len: 1948 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1944 bytes from map-output for attempt_local815117721_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1944, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1944
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1944 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1948 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local815117721_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local815117721_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local815117721_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local815117721_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local815117721_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local815117721_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local815117721_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local815117721_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8090
		FILE: Number of bytes written=595760
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1925
		Map output materialized bytes=1948
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1948
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=1646
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1099439552_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1099439552_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1099439552_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@747b63c
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+1908
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1925; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214384(104857536); length = 13/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1099439552_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1099439552_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1099439552_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1099439552_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6deb9086
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@48d51257
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1099439552_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1099439552_0001_m_000000_0 decomp: 1944 len: 1948 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1944 bytes from map-output for attempt_local1099439552_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1944, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1944
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1944 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1948 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1858 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1099439552_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1099439552_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1099439552_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1099439552_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1099439552_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1099439552_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1099439552_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1099439552_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=8090
		FILE: Number of bytes written=598792
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=1925
		Map output materialized bytes=1948
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=1948
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1908
	File Output Format Counters 
		Bytes Written=1638
INFO main com.ning.crawler.FTPUtil - FTP的端口错误,请正确配置
ERROR main com.ning.crawler.FTPUtil - 文件解析失败
ERROR main com.ning.crawler.FTPUtil - FTP关闭失败
INFO main com.ning.crawler.FTPUtil - FTP的端口错误,请正确配置
ERROR main com.ning.crawler.FTPUtil - 文件解析失败
ERROR main com.ning.crawler.FTPUtil - FTP关闭失败
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local903273771_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local903273771_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local903273771_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@535fd5ba
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 12258; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214396(104857584); length = 1/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local903273771_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local903273771_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local903273771_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local903273771_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@ac574e4
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@41451070
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local903273771_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local903273771_0001_m_000000_0 decomp: 12266 len: 12270 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 12266 bytes from map-output for attempt_local903273771_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 12266, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12266
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 10721 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 12266 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 12270 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 10721 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local903273771_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local903273771_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local903273771_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local903273771_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local903273771_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local903273771_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local903273771_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local903273771_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=38862
		FILE: Number of bytes written=639765
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=12258
		Map output materialized bytes=12270
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=12270
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=466092032
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=14631
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local618362150_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local618362150_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local618362150_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7dfaac49
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO main org.apache.hadoop.mapreduce.Job - Job job_local618362150_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7360; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local618362150_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local618362150_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local618362150_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local618362150_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@30ff446c
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@edeb859
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local618362150_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local618362150_0001_m_000000_0 decomp: 7422 len: 7426 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 7422 bytes from map-output for attempt_local618362150_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 7422, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7422
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 7422 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7426 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local618362150_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local618362150_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local618362150_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local618362150_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local618362150_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local618362150_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local618362150_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=29174
		FILE: Number of bytes written=617008
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=16
		Map output records=16
		Map output bytes=7360
		Map output materialized bytes=7426
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=16
		Reduce shuffle bytes=7426
		Reduce input records=16
		Reduce output records=16
		Spilled Records=32
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=6406
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local449584863_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local449584863_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local449584863_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7fde5210
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7360; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local449584863_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local449584863_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local449584863_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local449584863_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@8504f5b
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@211f74ff
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local449584863_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local449584863_0001_m_000000_0 decomp: 7422 len: 7426 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 7422 bytes from map-output for attempt_local449584863_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 7422, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7422
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 7422 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7426 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local449584863_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local449584863_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local449584863_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local449584863_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local449584863_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local449584863_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local449584863_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local449584863_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=29174
		FILE: Number of bytes written=617008
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=16
		Map output records=16
		Map output bytes=7360
		Map output materialized bytes=7426
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=16
		Reduce shuffle bytes=7426
		Reduce input records=16
		Reduce output records=16
		Spilled Records=32
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=6406
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1757330674_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1757330674_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1757330674_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1cf5ab7a
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7360; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1757330674_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1757330674_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1757330674_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1757330674_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@20f42345
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@73eb8b42
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1757330674_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1757330674_0001_m_000000_0 decomp: 7422 len: 7426 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 7422 bytes from map-output for attempt_local1757330674_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 7422, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7422
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 7422 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7426 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1757330674_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1757330674_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1757330674_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1757330674_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1757330674_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1757330674_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1757330674_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1757330674_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=29174
		FILE: Number of bytes written=620048
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=16
		Map output records=16
		Map output bytes=7360
		Map output materialized bytes=7426
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=16
		Reduce shuffle bytes=7426
		Reduce input records=16
		Reduce output records=16
		Spilled Records=32
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=6406
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1015567029_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1015567029_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1015567029_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1617846
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7360; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1015567029_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1015567029_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1015567029_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1015567029_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7cca6a13
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5a2bae36
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1015567029_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1015567029_0001_m_000000_0 decomp: 7422 len: 7426 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 7422 bytes from map-output for attempt_local1015567029_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 7422, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7422
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 7422 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7426 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1015567029_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1015567029_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1015567029_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1015567029_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1015567029_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1015567029_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1015567029_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1015567029_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=29174
		FILE: Number of bytes written=620048
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=16
		Map output records=16
		Map output bytes=7360
		Map output materialized bytes=7426
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=16
		Reduce shuffle bytes=7426
		Reduce input records=16
		Reduce output records=16
		Spilled Records=32
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=6406
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local757906584_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local757906584_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local757906584_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@77e0cb7
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7360; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local757906584_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local757906584_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local757906584_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local757906584_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@46045674
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1430683b
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local757906584_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local757906584_0001_m_000000_0 decomp: 3622 len: 3626 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 3622 bytes from map-output for attempt_local757906584_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 3622, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3622
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 3564 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 3622 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 3626 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 3564 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local757906584_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local757906584_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local757906584_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local757906584_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local757906584_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local757906584_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local757906584_0001_r_000001_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3942b506
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7a0f0d80
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local757906584_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local757906584_0001_m_000000_0 decomp: 3802 len: 3806 to MEMORY
INFO main org.apache.hadoop.mapreduce.Job - Job job_local757906584_0001 running in uber mode : false
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 3802 bytes from map-output for attempt_local757906584_0001_m_000000_0
INFO localfetcher#2 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 3802, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->3802
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 3745 bytes
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 50%
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 3802 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 3806 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 3745 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local757906584_0001_r_000001_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local757906584_0001_r_000001_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local757906584_0001_r_000001_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local757906584_0001_r_000001
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local757906584_0001_r_000001_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local757906584_0001_r_000001_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local757906584_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=44659
		FILE: Number of bytes written=925505
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=16
		Map output records=16
		Map output bytes=7360
		Map output materialized bytes=7432
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=16
		Reduce shuffle bytes=7432
		Reduce input records=16
		Reduce output records=16
		Spilled Records=32
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=698351616
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=6418
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1984194265_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1984194265_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1984194265_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4014de4c
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7360; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1984194265_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1984194265_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1984194265_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1984194265_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@8504f5b
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@211f74ff
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1984194265_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1984194265_0001_m_000000_0 decomp: 7422 len: 7426 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 7422 bytes from map-output for attempt_local1984194265_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 7422, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7422
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 7422 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7426 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1984194265_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1984194265_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1984194265_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1984194265_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1984194265_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1984194265_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1984194265_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1984194265_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=29174
		FILE: Number of bytes written=620048
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=16
		Map output records=16
		Map output bytes=7360
		Map output materialized bytes=7426
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=16
		Reduce shuffle bytes=7426
		Reduce input records=16
		Reduce output records=16
		Spilled Records=32
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=6406
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local412422169_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local412422169_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local412422169_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@73d26429
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+11975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 12170; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214300(104857200); length = 97/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local412422169_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local412422169_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local412422169_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local412422169_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@596776d4
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2cc057ce
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local412422169_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local412422169_0001_m_000000_0 decomp: 12270 len: 12274 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 12270 bytes from map-output for attempt_local412422169_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 12270, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12270
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12212 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 12270 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 12274 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12212 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local412422169_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local412422169_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local412422169_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local412422169_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local412422169_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local412422169_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local412422169_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local412422169_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=48876
		FILE: Number of bytes written=635417
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=12170
		Map output materialized bytes=12274
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=25
		Reduce shuffle bytes=12274
		Reduce input records=25
		Reduce output records=25
		Spilled Records=50
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11975
	File Output Format Counters 
		Bytes Written=10253
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1308612372_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1308612372_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1308612372_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6dadc688
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/C:/Users/ningjianjian/Desktop/custom/input.txt:0+11975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1308612372_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 12170; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214300(104857200); length = 97/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1308612372_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1308612372_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1308612372_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1308612372_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@c48e28d
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7d6ddcba
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1308612372_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1308612372_0001_m_000000_0 decomp: 12270 len: 12274 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 12270 bytes from map-output for attempt_local1308612372_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 12270, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12270
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12212 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 12270 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 12274 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12212 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1308612372_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1308612372_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1308612372_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1308612372_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1308612372_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1308612372_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1308612372_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=48876
		FILE: Number of bytes written=638457
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=12170
		Map output materialized bytes=12274
		Input split bytes=117
		Combine input records=0
		Combine output records=0
		Reduce input groups=25
		Reduce shuffle bytes=12274
		Reduce input records=25
		Reduce output records=25
		Spilled Records=50
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=535298048
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=11975
	File Output Format Counters 
		Bytes Written=10253
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local5351611_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local5351611_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local5351611_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@d286101
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7360; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local5351611_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local5351611_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local5351611_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local5351611_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3497c8f1
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@16b0d874
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local5351611_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local5351611_0001_m_000000_0 decomp: 7422 len: 7426 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 7422 bytes from map-output for attempt_local5351611_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 7422, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7422
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 7422 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7426 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local5351611_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local5351611_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local5351611_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local5351611_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local5351611_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local5351611_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local5351611_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local5351611_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=29174
		FILE: Number of bytes written=610936
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=16
		Map output records=16
		Map output bytes=7360
		Map output materialized bytes=7426
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=16
		Reduce shuffle bytes=7426
		Reduce input records=16
		Reduce output records=16
		Spilled Records=32
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=466092032
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=6406
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1298818318_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1298818318_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1298818318_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6dadc688
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1298818318_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7360; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1298818318_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1298818318_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1298818318_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1298818318_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5a7f293d
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@5f4e1b6b
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1298818318_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1298818318_0001_m_000000_0 decomp: 7422 len: 7426 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 7422 bytes from map-output for attempt_local1298818318_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 7422, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7422
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 7422 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7426 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1298818318_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1298818318_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1298818318_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1298818318_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1298818318_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1298818318_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1298818318_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=29174
		FILE: Number of bytes written=620048
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=16
		Map output records=16
		Map output bytes=7360
		Map output materialized bytes=7426
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=16
		Reduce shuffle bytes=7426
		Reduce input records=16
		Reduce output records=16
		Spilled Records=32
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=9
		Total committed heap usage (bytes)=539492352
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=6406
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local2105172052_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local2105172052_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2105172052_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@50d4e3bb
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7360; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local2105172052_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local2105172052_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2105172052_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local2105172052_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@443d4923
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@291dac14
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local2105172052_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local2105172052_0001_m_000000_0 decomp: 7422 len: 7426 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 7422 bytes from map-output for attempt_local2105172052_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 7422, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7422
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 7422 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7426 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local2105172052_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local2105172052_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local2105172052_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local2105172052_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local2105172052_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local2105172052_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local2105172052_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local2105172052_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=29174
		FILE: Number of bytes written=620048
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=16
		Map output records=16
		Map output bytes=7360
		Map output materialized bytes=7426
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=16
		Reduce shuffle bytes=7426
		Reduce input records=16
		Reduce output records=16
		Spilled Records=32
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=6406
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local283833233_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local283833233_0001
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local283833233_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2e7ca2fb
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO main org.apache.hadoop.mapreduce.Job - Job job_local283833233_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO communication thread org.apache.hadoop.mapred.LocalJobRunner - map > sort
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map > sort
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 7360; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214336(104857344); length = 61/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local283833233_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local283833233_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local283833233_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local283833233_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3c042cec
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@76a6f751
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local283833233_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local283833233_0001_m_000000_0 decomp: 7422 len: 7426 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 7422 bytes from map-output for attempt_local283833233_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 7422, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->7422
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 7422 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 7426 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 7365 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local283833233_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local283833233_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local283833233_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local283833233_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local283833233_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local283833233_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local283833233_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=29174
		FILE: Number of bytes written=617008
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=16
		Map output records=16
		Map output bytes=7360
		Map output materialized bytes=7426
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=16
		Reduce shuffle bytes=7426
		Reduce input records=16
		Reduce output records=16
		Spilled Records=32
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=6406
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1499346455_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1499346455_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1499346455_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@10912553
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 12022; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214300(104857200); length = 97/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1499346455_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1499346455_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1499346455_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1499346455_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3a5b3128
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@59e39b0f
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1499346455_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1499346455_0001_m_000000_0 decomp: 12121 len: 12125 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 12121 bytes from map-output for attempt_local1499346455_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 12121, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12121
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12064 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 12121 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 12125 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12064 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1499346455_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1499346455_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1499346455_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1499346455_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1499346455_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1499346455_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1499346455_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1499346455_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=38572
		FILE: Number of bytes written=637992
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=12022
		Map output materialized bytes=12125
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=25
		Reduce shuffle bytes=12125
		Reduce input records=25
		Reduce output records=25
		Spilled Records=50
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=10253
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1366281365_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1366281365_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1366281365_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6208100a
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 12022; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214300(104857200); length = 97/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1366281365_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1366281365_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1366281365_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1366281365_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@443d4923
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@291dac14
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1366281365_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1366281365_0001_m_000000_0 decomp: 12121 len: 12125 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 12121 bytes from map-output for attempt_local1366281365_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 12121, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12121
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12064 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 12121 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 12125 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12064 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1366281365_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1366281365_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1366281365_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1366281365_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1366281365_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1366281365_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1366281365_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1366281365_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=38572
		FILE: Number of bytes written=637992
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=12022
		Map output materialized bytes=12125
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=25
		Reduce shuffle bytes=12125
		Reduce input records=25
		Reduce output records=25
		Spilled Records=50
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=10253
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local823422779_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local823422779_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local823422779_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@646f806a
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 12022; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214300(104857200); length = 97/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local823422779_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local823422779_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local823422779_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local823422779_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@46045674
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1430683b
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local823422779_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local823422779_0001_m_000000_0 decomp: 12121 len: 12125 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 12121 bytes from map-output for attempt_local823422779_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 12121, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12121
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12064 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 12121 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 12125 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12064 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local823422779_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local823422779_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local823422779_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local823422779_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local823422779_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local823422779_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local823422779_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local823422779_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=38572
		FILE: Number of bytes written=634952
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=12022
		Map output materialized bytes=12125
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=25
		Reduce shuffle bytes=12125
		Reduce input records=25
		Reduce output records=25
		Spilled Records=50
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=10253
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local30709060_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local30709060_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local30709060_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1b33abcf
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO main org.apache.hadoop.mapreduce.Job - Job job_local30709060_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO communication thread org.apache.hadoop.mapred.LocalJobRunner - map > map
INFO main org.apache.hadoop.mapreduce.Job -  map 49% reduce 0%
INFO communication thread org.apache.hadoop.mapred.LocalJobRunner - map > map
INFO main org.apache.hadoop.mapreduce.Job -  map 53% reduce 0%
INFO communication thread org.apache.hadoop.mapred.LocalJobRunner - map > map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map > map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 12022; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214300(104857200); length = 97/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local30709060_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local30709060_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local30709060_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local30709060_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2dde8f6c
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@426883ff
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local30709060_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local30709060_0001_m_000000_0 decomp: 12121 len: 12125 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 12121 bytes from map-output for attempt_local30709060_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 12121, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12121
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12064 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 12121 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 12125 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12064 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local30709060_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local30709060_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local30709060_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local30709060_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local30709060_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local30709060_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local30709060_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=38572
		FILE: Number of bytes written=631912
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=12022
		Map output materialized bytes=12125
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=25
		Reduce shuffle bytes=12125
		Reduce input records=25
		Reduce output records=25
		Spilled Records=50
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=536870912
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=10253
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local956235321_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local956235321_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local956235321_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@657d9632
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO main org.apache.hadoop.mapreduce.Job - Job job_local956235321_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO communication thread org.apache.hadoop.mapred.LocalJobRunner - map > map
INFO main org.apache.hadoop.mapreduce.Job -  map 41% reduce 0%
INFO communication thread org.apache.hadoop.mapred.LocalJobRunner - map > map
INFO main org.apache.hadoop.mapreduce.Job -  map 53% reduce 0%
INFO communication thread org.apache.hadoop.mapred.LocalJobRunner - map > map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map > map
INFO main org.apache.hadoop.mapreduce.Job -  map 57% reduce 0%
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 12022; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214300(104857200); length = 97/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local956235321_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local956235321_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local956235321_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local956235321_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5e1ebdb3
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@45728c9d
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local956235321_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local956235321_0001_m_000000_0 decomp: 12121 len: 12125 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 12121 bytes from map-output for attempt_local956235321_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 12121, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12121
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12064 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 12121 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 12125 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12064 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local956235321_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local956235321_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local956235321_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local956235321_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local956235321_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local956235321_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local956235321_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=38572
		FILE: Number of bytes written=634952
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=12022
		Map output materialized bytes=12125
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=25
		Reduce shuffle bytes=12125
		Reduce input records=25
		Reduce output records=25
		Spilled Records=50
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=16
		Total committed heap usage (bytes)=504365056
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=10253
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1385178350_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1385178350_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1385178350_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6410b4c5
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1385178350_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 0% reduce 0%
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 12022; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214300(104857200); length = 97/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1385178350_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1385178350_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1385178350_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1385178350_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@63f906b1
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@267b6b4
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1385178350_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1385178350_0001_m_000000_0 decomp: 12121 len: 12125 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 12121 bytes from map-output for attempt_local1385178350_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 12121, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12121
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12064 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 12121 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 12125 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12064 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1385178350_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1385178350_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1385178350_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1385178350_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1385178350_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1385178350_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1385178350_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=38572
		FILE: Number of bytes written=637992
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=12022
		Map output materialized bytes=12125
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=25
		Reduce shuffle bytes=12125
		Reduce input records=25
		Reduce output records=25
		Spilled Records=50
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=466092032
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=10253
INFO main org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id
INFO main org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
WARN main org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
INFO main org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input paths to process : 1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1
INFO main org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1398591473_0001
INFO main org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/
INFO main org.apache.hadoop.mapreduce.Job - Running job: job_local1398591473_0001
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null
INFO Thread-3 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1398591473_0001_m_000000_0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@18e0d1c2
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Processing split: file:/D:/Project/test/BIO/NCBI/nr/input/nrtest.gz:0+6975
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - soft limit at 83886080
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
WARN LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.zlib.ZlibFactory - Failed to load/initialize native-zlib library
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.io.compress.CodecPool - Got brand-new decompressor [.gz]
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - 
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Starting flush of map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Spilling map output
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 12022; bufvoid = 104857600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214300(104857200); length = 97/6553600
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.MapTask - Finished spill 0
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task:attempt_local1398591473_0001_m_000000_0 is done. And is in the process of committing
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - map
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.Task - Task 'attempt_local1398591473_0001_m_000000_0' done.
INFO LocalJobRunner Map Task Executor #0 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1398591473_0001_m_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1398591473_0001_r_000000_0
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1
INFO pool-3-thread-1 org.apache.hadoop.yarn.util.ProcfsBasedProcessTree - ProcfsBasedProcessTree currently is supported only on Linux.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3b0870f0
INFO pool-3-thread-1 org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@761d516b
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=1323407744, maxSingleShuffleLimit=330851936, mergeThreshold=873449152, ioSortFactor=10, memToMemMergeOutputsThreshold=10
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1398591473_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1398591473_0001_m_000000_0 decomp: 12121 len: 12125 to MEMORY
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 12121 bytes from map-output for attempt_local1398591473_0001_m_000000_0
INFO localfetcher#1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 12121, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->12121
INFO EventFetcher for fetching Map Completion Events org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12064 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 12121 bytes to disk to satisfy reduce memory limit
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 12125 bytes from disk
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Merging 1 sorted segments
INFO pool-3-thread-1 org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 12064 bytes
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task:attempt_local1398591473_0001_r_000000_0 is done. And is in the process of committing
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task attempt_local1398591473_0001_r_000000_0 is allowed to commit now
INFO pool-3-thread-1 org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1398591473_0001_r_000000_0' to file:/C:/Users/ningjianjian/Desktop/custom/output/_temporary/0/task_local1398591473_0001_r_000000
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce
INFO pool-3-thread-1 org.apache.hadoop.mapred.Task - Task 'attempt_local1398591473_0001_r_000000_0' done.
INFO pool-3-thread-1 org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1398591473_0001_r_000000_0
INFO Thread-3 org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1398591473_0001 running in uber mode : false
INFO main org.apache.hadoop.mapreduce.Job -  map 100% reduce 100%
INFO main org.apache.hadoop.mapreduce.Job - Job job_local1398591473_0001 completed successfully
INFO main org.apache.hadoop.mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=38572
		FILE: Number of bytes written=637992
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=12022
		Map output materialized bytes=12125
		Input split bytes=114
		Combine input records=0
		Combine output records=0
		Reduce input groups=25
		Reduce shuffle bytes=12125
		Reduce input records=25
		Reduce output records=25
		Spilled Records=50
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=7
		Total committed heap usage (bytes)=462422016
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=6975
	File Output Format Counters 
		Bytes Written=10253
